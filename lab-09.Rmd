---
title: "Lab 09 - Grading the professor, Pt. 1"
author: "Fiona Wang"
date: "Mar-20-2025"
output: github_document
---

## Load Packages and Data

```{r load-packages, message=FALSE}
library(tidyverse) 
library(tidymodels)
library(openintro)
```

## Exercise 1 Getting to know the data

```{r loaddata}
data <- evals
```

```{r scorehist, message = FALSE}
data %>% 
  ggplot(aes(x = score)) + geom_histogram(binwidth = 0.1, color = "black")
```

As we can see from the graph, the majority of the data is on the right, and the tail extends to the left. Thus it is left-skewed. It doesn't show me a lot of details about students' rate. I want to include a boxplot and the summary statistics here too. 
```{r scorebox}
data %>% 
  ggplot(aes(y = score)) + geom_boxplot()
summary(data$score)
```

The mean rating is 4.18. Students were, on average, pretty satisfied with their professors. With a max of 5, and a min of 2.3. There are also 3 outliers on the lower end according to the boxplot. This is what I expected. Students rated on 463 courses taught by 94 professors, so I expected this variance. I think an average of 4.18 is fair and pretty good. 

## Exercise 2 Visual

```{r scorebty}
data %>% 
  ggplot(aes(x = bty_avg, y = score)) + geom_point(alpha = 0.2, color = "blue") + 
  labs(title = "Relationship Between Beauty Rating and Overall Ratings for Professors")
```

I made the dots transparent. For the darker dots, it means that more people rated appearance and score that way. According to this graph, I think there is a positive relationship between score and beauty rating. However, it's not very clear. There could be no relationship too because the dots are pretty scattered all over the place. 

### Exercise 3 Visual improve
```{r jitter}
data %>% 
  ggplot(aes(x = bty_avg, y = score)) + geom_jitter() + 
  labs(title = "Relationship Between Beauty Rating and Overall Ratings for Professors")
```

I don't know what jitter means, so I looked it up in the Help panel. It says that jitter "adds a small amount of random variation to the location fo each point". It can help with reducing overlap, especially for our dataset which has a lot of overlapping points. This means that the first graph might be misleading because we can't see all the data as they were stacked on top of each other. However, I made the dots transparent, so I still retained this information. 

### Exercise 4 Beauty model
```{r}
m_bty <- linear_reg() %>% 
  set_engine("lm") %>% 
  fit(score ~ bty_avg, data = data)
tidy(m_bty)
```

From the output table, the linear model will be:
score = 3.88 + 0.067(bty_avg)

### Exercise 5 Visual with regression line
```{r replot, message=FALSE}
data %>% 
  ggplot(aes(x = bty_avg, y = score)) + geom_jitter() + geom_smooth(method = "lm", se = FALSE) + 
  labs(title = "Relationship Between Beauty Rating and Overall Ratings for Professors",
       x = "Average Beauty Rating",
       y = "Average Professor Evaluation")
```

### Exercise 6 Interpreting the slope
Looking at the table from exercise 4, the slope of the linear model is 0.0666. This means that with one unit increase in average beauty rating, there will be a 0.0666 unit increase in the average professor evaluation. 


### Exercise 7 Interpreting the intercept
Again, looking at the table from exercise 4, the intercept is 3.88. This means that when there is a 0 for the average beauty rating for a professor, the average professor evaluation (score) is 3.88. Theoretically, this makes sense. However, in the context of this data, the intercept doesn't make sense. I checked the description of this data. The beauty ratings are from 1-10. Thus, there wouldn't be a 0 for the average beauty rating. 

### Exercise 8 Interpreting R^2
```{r Rsquared}
glance(m_bty)
```

The R^2 is 0.035. Sine we only have one predictor, I just looked at the R^2, and not the adjusted R^2. This means that the average beauty rating explained 3.5% of the variance in the average professor evaluation. 

### Exercise 9 Gender model and interpretation
```{r gendermodel}
m_gen <- linear_reg() %>% 
  set_engine("lm") %>% 
  fit(score ~ gender, data = data)
tidy(m_gen)
```

The linear model:       
y = 4.093 + 0.142x       
Score = 4.093 + 0.142(gender)         
The slope is 0.142. This means that with one unit increase in gender, the score increases by 0.142 unit. However, I cannot tell from the data the numeric representation for each gender. The intercept is 4.093. This means that when the gender is 0, the average professor evaluation score is 4.093.     
I am curious to find out which gender is represented by 0. Let's calculate the mean score for each gender.   
```{r meangender}
data %>% 
  group_by(gender) %>% 
  summarise(mean_score = mean(score, na.rm = TRUE))
```

As we see from the table, females have an average score of 4.0928. This tells me that females are denoted as 0, and males as 1. Now let's interpret the slope and intercept once again with this information in mind. We have an intercept of 4.093. This means that females had an average of 4.093 in score. Males, on average, had a 0.142 higher score in rating than females.
The 0 here makes sense in the context of the data.

### Exercise 10 More on gender
Based on the previous exercise, we can write down the equation for each gender.     
Female: score = 4.093 + 0.142(0) = 4.093.     
Male: score = 4.093 + 0.142(1) = 4.235

### Exercise 11 Rank model
```{r rankmodel}
m_rank <- linear_reg() %>% 
  set_engine("lm") %>% 
  fit(score ~ rank, data = data)
tidy(m_rank)
```

There are two slopes.       
The overall equation is: score = 4.284 -0.1297(x1) - 0.1452(x2)
Again, I want to have an idea of how these three categories are represented using numerical values.
```{r meanrank}
data %>% 
  group_by(rank) %>% 
  summarise(mean_score = mean(score, na.rm=TRUE))
```

It seems like teaching is the reference group. There are two slopes. The first slope (-0.13) is for the tenure track group, and the reference group is the teaching group, score = 4.284 - 0.13(1) - 0.15(0) = 4.155. This means that when the rank is 0 (teaching group), the mean score is 4.284, which is the intercept. With one unit increase in rank, there will be a 0.13 unit decrease in score. One unit increase in rank refers to the tenure track group. So, the tenure track group has an average scoring of 4.155.      
The second slope (-0.145) is for the tenured group, and the reference group is the teaching group, score = 4.284 - 0.13(0) - 0.145(1) = 4.139. This means that when the rank is 0 (teaching group), the mean score is 4.284, which is the intercept. With one unit increase in rank, there will be a 0.145 unit decrease in score. One unit increase in rank refers to the tenured group in this equation. So, the tenured group has an average scoring of 4.139.

### Exercise 12 Creating rank_relevel
```{r createvar}
data$rank_relevel <- relevel(data$rank, ref = "tenure track")
levels(data$rank)
levels(data$rank_relevel)
```

### Exercise 13 Rank_relevel model
Now that the reference group is tenure track, let's fit another regression model. 
```{r rankrefit}
m_rank_relevel <- linear_reg() %>% 
  set_engine("lm") %>% 
  fit(score ~ rank_relevel, data = data)
tidy(m_rank_relevel)
glance(m_rank_relevel)
```

There are two slopes, and the reference group is tenure track.    
The overall model: score = 4.155 + 0.1297(teaching) - 0.0155(tenured).     
The first slope is 0.1297. One unit increase in rank is associated with 0.1297 increase in the average score. One unit increase here refers to the teaching group, and they have a 4.155 + 0.1297(1) - 0.0155(0) = 4.2843 average rating.     
The second slope is -0.0155. One unit increase in rank is associated with 0.0155 decrease in the average score. One unit increase here is the tenured group, and they have a 4.155 + 0.1297(0) - 0.0155(1) = 4.139 average rating.     
The R^2 is 0.0116. This means that rank explains 1.16% of the variance in average scores. Also, it is not significant. Rank is not a significant predictor of score. 

### Exercise 14
